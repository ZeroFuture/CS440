{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class DATA():\n",
    "    def __init__(self, matrix, label):\n",
    "        self.matrix = matrix\n",
    "        self.label = label\n",
    "        self.dist = 0\n",
    "        self.feature = None\n",
    "        \n",
    "    def __eq__(self, img):\n",
    "        return 0\n",
    "    \n",
    "    def __lt__(self, img):\n",
    "        return self.dist < img.dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(source, classified):\n",
    "    if classified:\n",
    "        digits_data = {}\n",
    "    else:\n",
    "        digits_data = []\n",
    "        \n",
    "    with open(source) as f:\n",
    "        matrix = []\n",
    "        vector = []\n",
    "        for line in f:\n",
    "            if len(line) > 10:\n",
    "                for element in line.rstrip():  \n",
    "                    vector.append(int(element))\n",
    "                matrix.append(line.rstrip())\n",
    "            else:\n",
    "                class_idx = int(line.rstrip())\n",
    "                observation = DATA(matrix, class_idx)\n",
    "                observation.feature = np.array(vector)\n",
    "                \n",
    "                if classified:\n",
    "                    if class_idx not in digits_data:\n",
    "                        digits_data[class_idx] = [observation]\n",
    "                    else:\n",
    "                        digits_data[class_idx] = digits_data[class_idx] + [observation]\n",
    "                    matrix = []\n",
    "                    vector = []    \n",
    "                else:\n",
    "                    digits_data.append(observation)\n",
    "                    matrix = []\n",
    "                    vector = []\n",
    "                    \n",
    "    return digits_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2.1: _Non-differentiable Perceptron:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the multi-class (non-differentiable) perceptron learning rule from lecture to the digit classification problem from Part 1.1. As before, the basic feature set consists of a single binary indicator feature for each pixel. Specifically, the feature $F_{i,j}$ indicates the status of the (i,j)-th pixel. Its value is 1 if the pixel contains value 1, and 0 if it is 0. The images are of size 32*32, so there are 1024 features in total. For a multi-class perceptron, you need to learn a weight vector for each digit class. Each component of a weight vector corresponds to the weight of a pixel, which makes it of length either 1024 (without bias) or 1025 (with bias)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get your results, you should tune the following parameters (it is not necessary to separately report results for multiple settings, only report which options you tried and which one worked the best):\n",
    "\n",
    "- Learning rate decay function;\n",
    "- Bias vs. no bias;\n",
    "- Initialization of weights (zeros vs. random);\n",
    "- Ordering of training examples (fixed vs. random);\n",
    "- Number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import random\n",
    "\n",
    "\n",
    "def prediction_p(tst_data, w):\n",
    "    pred = {}\n",
    "    for class_idx in range(10):\n",
    "        tst_data_i = tst_data[class_idx]\n",
    "        label = []\n",
    "        for data in tst_data_i:\n",
    "            c = np.zeros((10,))\n",
    "            for i in range(10):\n",
    "                c[i] = data.feature @ w[i]\n",
    "            label.append(int(np.argmax(c)))\n",
    "        pred[class_idx] = label \n",
    "        \n",
    "    return pred\n",
    "\n",
    "def rate_helper(actual, predict):\n",
    "    sum = 0\n",
    "    for value in predict:\n",
    "        if value == actual:\n",
    "            sum += 1\n",
    "    return sum / len(predict)\n",
    "\n",
    "def correct_rate(pred_label):\n",
    "    rate = np.zeros((10,))\n",
    "    for i in range(10):\n",
    "        rate[i] = rate_helper(i, pred_label[i])\n",
    "    return rate\n",
    "\n",
    "def correct_rate_overall(pred_label):\n",
    "    hit = 0\n",
    "    total = 0\n",
    "    for i in range(10):\n",
    "        for label in pred_label[i]:\n",
    "            if label == i:\n",
    "                hit += 1\n",
    "            total += 1\n",
    "    return hit / total\n",
    "\n",
    "# This is a 10x10 matrix whose entry in row r and column c is \n",
    "# the percentage of test images from class r that are classified as class c\n",
    "def confusion_matrix(pred_label):\n",
    "    confusion = np.zeros((10, 10))\n",
    "    for r in range(10):\n",
    "        class_r = pred_label[r]\n",
    "        num_cor = np.zeros((10,))\n",
    "        total = 0\n",
    "        for label in class_r:\n",
    "            num_cor[label] += 1\n",
    "            total += 1\n",
    "        confusion[r] = num_cor / total\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import overall training data\n",
    "trn_data_unclassified = import_data(\"optdigits-orig_train.txt\", classified = False)\n",
    "trn_data = import_data(\"optdigits-orig_train.txt\", classified = True)\n",
    "tst_data = import_data(\"optdigits-orig_test.txt\", classified = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _**Implementing the Perceptron:**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def perceptron(trn_data_unclassified, trn_data, epochs, bias, random_ordering, w):\n",
    "    results = {}\n",
    "    # Start:\n",
    "    for n in range(epochs):\n",
    "        train_data = copy.deepcopy(trn_data_unclassified)\n",
    "        if random_ordering:\n",
    "            random.shuffle(train_data)\n",
    "\n",
    "        for idx, digit in enumerate(train_data):\n",
    "            eta = 1 / (0.001 * idx + 1) # Learning rate decay function\n",
    "            \n",
    "            c = np.zeros((10,))\n",
    "            for class_idx in range(10):\n",
    "                c[class_idx] = digit.feature @ w[class_idx] + bias\n",
    "            pred = np.argmax(c)\n",
    "            \n",
    "            if digit.label != pred:\n",
    "                w[pred] = w[pred] - eta * digit.feature\n",
    "                w[digit.label] = w[digit.label] + eta * digit.feature\n",
    "                \n",
    "\n",
    "        pred = prediction_p(trn_data, w)\n",
    "        rate_overall = correct_rate_overall(pred)\n",
    "        results[n+1] = rate_overall\n",
    "        if rate_overall == 1:\n",
    "            return results\n",
    "\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _**Setting the Tuning Parameters and start learning**_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w = np.random.rand(10, 1024)\n",
    "epochs = 30\n",
    "bias = 0\n",
    "random_ordering = True\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "results = perceptron(trn_data_unclassified, trn_data, epochs, bias, random_ordering, w)\n",
    "pred = prediction_p(tst_data, w)\n",
    "rate_overall = correct_rate_overall(pred)\n",
    "confusion = confusion_matrix(pred)\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "print(\"Overall Test Accuracy: {}\\n\".format(rate_overall))\n",
    "print(\"Confusion Matrix:\")\n",
    "np.set_printoptions(precision=4)\n",
    "print(confusion)\n",
    "\n",
    "n_epochs = list(results.keys())\n",
    "trn_correct_rate = list(results.values())\n",
    "plt.xlabel('number of epochs')\n",
    "plt.ylabel('overall train correction rate')\n",
    "plt.title('epochs vs performance')\n",
    "plt.plot(n_epochs, trn_correct_rate, 'bo-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- _**Discussion:**_\n",
    "\n",
    "    - From the above code, it seems that when the ordering is random, bias doesn't really matter. Here we set bias = 0.\n",
    "    - The decay training function is: $\\eta = \\frac{1}{0.001 * n + 1}$ with nth sample and decay rate 0.001."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.2: _Digit Classification with Nearest Neighbor:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a k-nearest-neighbor classifier for the digit classification task in Part 2.1. You should play around with different choices of distance or similarity function to find what works the best. In the report, please discuss your choice of distance/similarity function, and give the overall accuracy on the test set as a function of k (for some reasonable range of k, from 1 to 25, you can describe this function with a table and discuss a general trend). For the best choice of k, give the confusion matrix. As a baseline, report the running time for a single query (classify a single instance in the test dataset) by using brute force. Discuss how you can optimize its performance. Finally, compare your nearest-neighbor accuracy to the accuracies you got with Naive Bayes and Perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import overall training data\n",
    "trn_data = import_data(\"optdigits-orig_train.txt\", classified = True)\n",
    "tst_data = import_data(\"optdigits-orig_test.txt\", classified = True)\n",
    "len(trn_data[0][0].feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue as Q\n",
    "\n",
    "def manhattanDist(img1, img2):\n",
    "    dist = 0\n",
    "    for i in range(32):\n",
    "        for j in range(32):\n",
    "            if img1[i][j] != img2[i][j]:\n",
    "                dist += 1\n",
    "    return dist\n",
    "\n",
    "def cosineSimilarity(img1, img2):\n",
    "    dist = 0\n",
    "    img1_total = 0\n",
    "    img2_total = 0\n",
    "    for i in range(32*32):\n",
    "            dist += img1[i] and img2[i]\n",
    "            if img1[i]: img1_total += 1\n",
    "            if img2[i]: img2_total += 1    \n",
    "    return dist/(img1_total*img2_total)\n",
    "    \n",
    "\n",
    "def knn_manhattanDist(trn_data, tst_data, k):\n",
    "    conf_mat = np.zeros((10, 10))\n",
    "    hit = 0\n",
    "    total = 0\n",
    "    for i in range(10):\n",
    "        for tst_data_i in tst_data[i]:\n",
    "#             knn_i = []\n",
    "            knn_freq = np.zeros(10)\n",
    "            neighbor_dist_queue = Q.PriorityQueue(maxsize=k)\n",
    "            for j in range(10):\n",
    "                for trn_data_j in trn_data[j]:\n",
    "                    dist = manhattanDist(tst_data_i.matrix, trn_data_j.matrix)\n",
    "                    trn_data_j.dist = dist\n",
    "                    neighbor_dist_queue.put((dist, trn_data_j))\n",
    "            for kth in range(k):\n",
    "                kth_nearest = neighbor_dist_queue.get()[1]\n",
    "#                 knn_i.append(kth_nearest)\n",
    "                knn_freq[kth_nearest.label] += 1\n",
    "            print(\"hi\")\n",
    "            pred_label = int(np.argmax(knn_freq))\n",
    "            conf_mat[i][pred_label] += 1/len(tst_data[i])\n",
    "            if pred_label == i: hit += 1\n",
    "            total += 1\n",
    "    return conf_mat, np.diag(conf_mat), hit/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "for k in range(1, 26): \n",
    "    conf_mat, cor_rate, cor_rate_total = knn(trn_data, tst_data, k)\n",
    "    print(conf_mat)\n",
    "    print(cor_rate)\n",
    "    print(cor_rate_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.3.1: _Weights Visualization_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    temp = w[i].reshape((32,32))\n",
    "    print(\"Weights for digit {}:\".format(i))\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.gca()\n",
    "    ax.set_xticks(np.arange(0.5, 32.5, 1))\n",
    "    ax.set_yticks(np.arange(0.5, 32.5, 1))\n",
    "    #plt.grid(color='w', linestyle='-', linewidth=1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(temp, interpolation='nearest', cmap = plt.cm.binary)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.3.2: _Differential Perceptron_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(trn_data_unclassified, trn_data, epochs, bias, random_ordering, w):\n",
    "    results = {}\n",
    "    # Start:\n",
    "    for n in range(epochs):\n",
    "        train_data = trn_data_unclassified[:]\n",
    "        if random_ordering:\n",
    "            random.shuffle(train_data)\n",
    "\n",
    "        for idx, digit in enumerate(train_data):\n",
    "            eta = 1 / (0.001 * idx + 1) # Learning rate decay function\n",
    "            for class_idx in range(10):\n",
    "                if digit.label == class_idx:\n",
    "                    y = 1\n",
    "                else:\n",
    "                    y = -1\n",
    "                if (digit.feature @ w[class_idx] + bias) * y <= 0:\n",
    "                    w[class_idx] = w[class_idx] + eta * y * digit.feature\n",
    "                \n",
    "        pred = prediction_p(trn_data, w)\n",
    "        rate_overall = correct_rate_overall(pred)\n",
    "        results[n+1] = rate_overall\n",
    "        if rate_overall == 1:\n",
    "            return results\n",
    "\n",
    "    return results\n",
    "\n",
    "#w = np.zeros((10, 1024))\n",
    "w = np.random.rand(10, 1024)\n",
    "epochs = 30\n",
    "bias = 0\n",
    "random_ordering = True\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "results = perceptron(trn_data_unclassified, trn_data, epochs, bias, random_ordering, w)\n",
    "pred = prediction_p(tst_data, w)\n",
    "rate_overall = correct_rate_overall(pred)\n",
    "confusion = confusion_matrix(pred)\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "print(\"Overall Test Accuracy: {}\\n\".format(rate_overall))\n",
    "print(\"Confusion Matrix:\")\n",
    "np.set_printoptions(precision=4)\n",
    "print(confusion)\n",
    "\n",
    "n_epochs = list(results.keys())\n",
    "trn_correct_rate = list(results.values())\n",
    "plt.xlabel('number of epochs')\n",
    "plt.ylabel('overall train correction rate')\n",
    "plt.title('epochs vs performance')\n",
    "plt.plot(n_epochs, trn_correct_rate, 'bo-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
